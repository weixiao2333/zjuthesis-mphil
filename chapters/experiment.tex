\chapter{实验与讨论}
本章对前面提到的所有模型都设计了相应的实验，同时做了多组对照试验，以验证我们对模型改进的可行性和有效性。

\section{实验数据集与预处理}
\subsection{实验数据集}
实验开始前调研了与本文任务类似的数据集，调研结果发现高质量的可用于跨界服务平台的中文语料数据集相对匮乏,例如对话类数据集部分输入为语音而不是
文本，再如科大讯飞阿里小蜜有着海量有商业价值数据的公司没有公开数据集。为此，我们选择在已有数据集上做标注补充和扩展，构建了跨界服务相关的中文
预料数据集。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=15cm]{./images/count.jpg}
    \caption{数据集分布图}
    \label{fig:count}
  \end{figure}

SMP2019中文人机对话技术评测自然语言理解任务中提供了SMP2019ECDT数据集，其中主要包括垂直类，闲聊类和知识问答，我们结合跨界服务平台系统内部常用
服务，从垂直类中选择部分数据做标注扩充以及数据扩充。本文筛选了合跨界服务平台中用户使用较多的几类服务的语料信息，包括“航班flight”，“音乐music”，
“天气weather”，“火车train”，“地图map”，“股票stock”，“医疗medical”，“新闻news”共八大类服务，再根据这些服务的接口构建接口类别的全集，例如“query”,“play”,“order”等；同时确定了服务接口以后，服务接口调用
时的参数（语义槽）也就确定了,例如“songName”，“singer”，“startCity”，“endCity”等，可见接口和服务参数都是和服务强相关的。例如，当服务类型被判定为
“天气weather”时，接口类型为“query”，参数（语义槽）为“city”。

SMP2019ECDT数据集中与跨界服务平台系统内八大服务相关的数据量并不大，因此本文对原有数据集做了扩充。扩充工作主要分为两部分：横向扩充和纵向扩充，横向
扩充的直觉来源于同一个语义的句子不同人的表述会不同，例如“杭州具体天气怎么样？”和“杭州今天多少度？”，因此考虑对同种语义的句子做横向扩充，这里我们借助
了百度和必应（微软bing）两大搜索引擎的搜索联想补全功能。横向扩充完的句子标签中的服务类别和接口类别不用变，只需要修改语义槽标注。
如图\ref{fig:baidu}，\ref{fig:bing}所示,想要扩展火车服务的查询接口的语料数据，再搜索引擎输入“成都到杭州火车”，利用搜索引擎的联想补全功能
达到扩充的目的。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=15cm]{./images/baidu.png}
    \caption{数据横向扩充图1}
    \label{fig:baidu}
  \end{figure}

  \begin{figure}[htbp]
    \centering
    \includegraphics[width=15cm]{./images/bing.png}
    \caption{数据横向扩充图2}
    \label{fig:bing}
  \end{figure}

数据集纵向扩充是组织跨界服务课题组和实验室同学填写问卷，让被调研者输入相应服务的查询语句，收集起来对语句进行人工标注，完成数据集的扩容。
每个人对同一语义的表达会有差异，有差异的数据对训练出泛化能力好的数据是大有裨益的。最终经过课题组同学的努力，共构建了19145条数据组成实验
数据集，每条数据都包含服务类别标签、接口类别标签和参数（语义槽）标签。



\subsection{预处理}

\section{评价指标}
评价指标用于评估模型的性能，对于服务分类任务，本文采用准确率（Accuracy）来评估模型；对于接口分类
任务，同样采用准确率（Accuracy）来评估模型；对于参数（语义槽）填充任务，采用$F_1$值来评估模型。同时引入
句子准确率（Sentence Accuracy)作为更严格的指标来评估模型，即一个句子只有在三项任务同时正确时才会被计入
句子准确率中。

 \begin{table}[htb]
      \centering
      \caption{服务类型混淆矩阵}
      \label{tab:hunxiao}
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{2}{|c|}{\multirow{2}{*}{}}&
    \multicolumn{8}{c|}{预测值}\\
    \cline{3-10}
    \multicolumn{2}{|c|}{}&flight & music & weather & train & map &stock &medical & news \\
     \hline
     \multirow{8}{*}{真实值}&
     flight&$n_1$&$n_2$&$n_3$&$n_4$&$n_5$&$n_6$&$n_7$&$n_8$\\
     \cline{2-10}
     \multicolumn{1}{|c|}{}&music&$n_{9}$&$n_{10}$&$n_{11}$&$n_{12}$&$n_{13}$&$n_{14}$&$n_{15}$&$n_{16}$\\
     \cline{2-10}
     \multicolumn{1}{|c|}{}&weather&$n_{17}$&$n_{18}$&$n_{19}$&$n_{20}$&$n_{21}$&$n_{22}$&$n_{23}$&$n_{24}$\\
     \cline{2-10}
     \multicolumn{1}{|c|}{}&train&$n_{25}$&$n_{26}$&$n_{27}$&$n_{28}$&$n_{29}$&$n_{30}$&$n_{31}$&$n_{32}$\\
     \cline{2-10}
     \multicolumn{1}{|c|}{}&map&$n_{33}$&$n_{34}$&$n_{35}$&$n_{36}$&$n_{37}$&$n_{38}$&$n_{39}$&$n_{40}$\\
     \cline{2-10}
     \multicolumn{1}{|c|}{}&stock&$n_{41}$&$n_{42}$&$n_{43}$&$n_{44}$&$n_{45}$&$n_{46}$&$n_{47}$&$n_{48}$\\
     \cline{2-10}
     \multicolumn{1}{|c|}{}&medical&$n_{49}$&$n_{50}$&$n_{51}$&$n_{52}$&$n_{53}$&$n_{54}$&$n_{55}$&$n_{56}$\\
     \cline{2-10}
     \multicolumn{1}{|c|}{}&news&$n_{57}$&$n_{58}$&$n_{59}$&$n_{60}$&$n_{61}$&$n_{62}$&$n_{63}$&$n_{64}$\\
    \hline
    \end{tabular}
  \end{table}

  以服务类别标签的混淆矩阵\ref{tab:hunxiao}为例介绍以上指标的计算方法,设样本数据总量是N。
  准确率（Accuracy）是最直观的性能指标，它是正确预测的观测值与总观测值的比率，如果具有很高的准确率，可以认为模型是很好的：
  \begin{equation}
  % \text {Accuracy}(\text {health})=\frac{\sum_{i=8}^{14} n_{i}}{N}
  \text {Accuracy}=\frac{n_1+n_{10}+n_{19}+n_{28}+n_{37}+n_{46}+n_{55}+n_{64}}{N}
\end{equation}
精确度（Precision）是正确预测的该类样本与总的预测为该类样本的观察值之比，多用于二分类问题，对于文本分类这样的多分类问题，可以单独取一个类别做计算，以天气类别为例：
\begin{equation}
  \text {Precision}(\text {weather})=\frac{n_{19}}{n_3+n_{11}+n_{19}+n_{27}+n_{35}+n_{43}+n_{51}+n_{69}}
\end{equation}
召回率（Recall)是正确预测的该类样本与实际为该类的样本总量的比率，多用于二分类问题，对于文本分类这样的多分类问题，可以单独取一个类别做计算，以天气类别为例：
\begin{equation}
  \text {Recall}(\text {weather})=\frac{n_{19}}{\sum_{i=17}^{24} n_{i}}
\end{equation}
F1值是精确度和召回率的调和平均值，直观上它不如准确性容易理解，但是F1通常比准确性更有用，尤其是在类分布不均匀的情况下：
\begin{equation}
  F_1=\frac{2 \times Precision \times Recall}{ Precision + Recall}
  % F_{1}=\frac{2 \times \text {Precision } \times \text { Recall}}{\text {Precision }+\text { Recall}}
\end{equation}

\section{实验设置}
\subsection{实验环境}
本文的实验环境是实验室服务器，操作系统为Ubuntu 16.04.4系统,集成开发环境选用Pycharm使用Python语言利用PyTorch框架编程。
关于实验室机器硬件配置，中央处理器为Intel(R) Xeon(R) CPU E5-2603 v3 @ 1.60GHz，图形处理器为GeForce RTX 2080Ti。

\begin{table}[htb]
  \centering
  \caption{实验环境}
  \label{tab:hunxiao}
\begin{tabular}{c|c}
\hline
实验环境&配置参数\\
\hline
操作系统&Ubuntu 16.04.4\\
编程语言&python 3.6\\
IDE&Pycharm\\
模型框架&PyTorch\\
\hline
\end{tabular}
\end{table}

\subsection{实验设计}
本文对前两章提到的所有模型都进行了实验，虽然模型数量较多，但总的来说可分为两类：基于词向量的模型和引入预训练的模型
\subsection{基于词向量的模型}
前文提到的attention-CNN-LSTM模型、Transformable-CNN-LSTM模型、BiLSTM-attention-CRF模型均是基于词向量的模型，实验流程类似。
第一步输入句子经过分词处理得到词序列，接着利用word2vec将词语向量化输入神经网络训练。训练集数据用于模型的拟合，验证集数据用于对模型超参数的调整以及对模型性能做初步判定，
测试集用来评估模型最终的泛化能力，不作为调参、特征等算法相关的选择依据。测试阶段加载训练好的模型参数，数据输入进入网络得到预测结果。
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.5]{./images/word2vecTrain.jpg}
  \caption{基于词向量模型的实验流程}
  \label{fig:word2vecTrain}
\end{figure}

\subsection{引入预训练的模型}
前文提到的单向联合识别模型、交互式联合识别模型、bert-base联合识别模型、引入bert的交互式联合识别模型均属于结合预训练的模型，实验流程类似。
首先加载预训练模型的参数，输入句子的字序列向量进入网络训练。训练集数据用于模型的拟合以及对预训练模型进行微调（fine-tuning），验证集数据用于对模型超参数的调整以及对模型性能做初步判定，
测试集用来评估模型最终的泛化能力，不作为调参、特征等算法相关的选择依据。测试阶段加载训练好的模型参数和预训练参数，数据输入进入网络得到预测结果。
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.5]{./images/bertTrain.jpg}
  \caption{引入预训练模型的实验流程}
  \label{fig:bertTrain}
\end{figure}



\section{实验结果与分析}fine-tuning